{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r6knIG8wNCn",
        "outputId": "6fabeea7-18e2-400d-d242-1b6b8c5ab2d5"
      },
      "outputs": [],
      "source": [
        "#importing everything required\n",
        "import random\n",
        "import pickle\n",
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    data = np.array(pd.read_csv('data.csv'))\n",
        "    np.random.shuffle(data)\n",
        "\n",
        "    train_data = data[0:60000].T\n",
        "    nx = train_data.shape[1]\n",
        "    train_X = train_data[1:nx]\n",
        "    train_X = train_X/255.0\n",
        "    train_Y = train_data[0]\n",
        "\n",
        "    test_data = data[60000:70000].T\n",
        "    nx = test_data.shape[1]\n",
        "    test_X = test_data[1:nx]\n",
        "    test_X = test_X/255.0\n",
        "    test_Y = test_data[0]\n",
        "\n",
        "    return train_X, train_Y, test_X, test_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_X data shape:  (784, 60000)\n",
            "train_Y data shape:  (60000,)\n",
            "test_X data shape:  (784, 10000)\n",
            "test_Y data shape:  (10000,)\n"
          ]
        }
      ],
      "source": [
        "train_X, train_Y , test_X, test_Y = load_data()\n",
        "print(\"train_X data shape: \", train_X.shape)\n",
        "print(\"train_Y data shape: \", train_Y.shape)\n",
        "print(\"test_X data shape: \", test_X.shape)\n",
        "print(\"test_Y data shape: \", test_Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "VOMKwm-HdG4v",
        "outputId": "10d8d568-c285-4772-fb16-2519293388d2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#showing sample image along with their label\n",
        "\n",
        "index = 4528\n",
        "temp = np.reshape(train_X.T[index], (28,28))\n",
        "plt.imshow(temp, cmap='gray')\n",
        "plt.title(str(train_Y[index]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DWiojCz06abA"
      },
      "outputs": [],
      "source": [
        "def sigmoid(Z):\n",
        "    A = 1/(1+np.exp(-Z))\n",
        "    return A, Z\n",
        "#print(sigmoid(0.5))\n",
        "\n",
        "def sigmoid_prime(Z):\n",
        "    s = sigmoid(Z)\n",
        "    dZ = s*(1-s)\n",
        "    return dZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RP_90CXA4H48"
      },
      "outputs": [],
      "source": [
        "def relu(Z):\n",
        "    A = np.maximum(0,Z)\n",
        "    assert(A.shape == Z.shape)\n",
        "    return A, Z\n",
        "\n",
        "def relu_prime(Z):\n",
        "    return Z>0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TG_qlUTT9nJc"
      },
      "outputs": [],
      "source": [
        "def softmax(Z):\n",
        "    A = np.exp(Z)/sum(np.exp(Z))\n",
        "    return A, Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhhxdJTF-3Gg",
        "outputId": "c6acd60f-e3d5-4d36-97bf-6743648b0b11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training examples: 60000\n",
            "Number of testing examples: 10000\n",
            "Each image is of size: 784 pixels\n"
          ]
        }
      ],
      "source": [
        "#size of train and test set and also each pixel value\n",
        "\n",
        "m_train = train_X.shape[1]\n",
        "num_px = train_X.shape[0]\n",
        "m_test = test_X.shape[1]\n",
        "\n",
        "print (\"Number of training examples: \" + str(m_train))\n",
        "print (\"Number of testing examples: \" + str(m_test))\n",
        "print (\"Each image is of size:\", num_px, \"pixels\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GI6LfNHAApdd"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters_deep(layer_dims):\n",
        "    np.random.seed(3)\n",
        "    parameters = {}\n",
        "    L = len(layer_dims) # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "        \n",
        "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
        "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "\n",
        "        \n",
        "    return parameters\n",
        "\n",
        "#print(initialize_parameters_deep([2, 4, 5, 4, 2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xdNtonxkTLke"
      },
      "outputs": [],
      "source": [
        "def normalize(Y):\n",
        "    normalized_Y = np.zeros((Y.size, 10))\n",
        "    normalized_Y[np.arange(Y.size), Y] = 1\n",
        "    normalized_Y = normalized_Y.T\n",
        "    return normalized_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6wutXkkhApkw"
      },
      "outputs": [],
      "source": [
        "def linear_forward(A, W, b):\n",
        "    Z = np.dot(W, A) + b\n",
        "    cache = (A, W, b)\n",
        "    return Z, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yMa9FctlAptm"
      },
      "outputs": [],
      "source": [
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "    Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "    if activation == \"sigmoid\":\n",
        "        A, activation_cache = sigmoid(Z)\n",
        "    elif activation == \"relu\":\n",
        "        A, activation_cache = relu(Z)\n",
        "    elif activation == \"softmax\":\n",
        "        A, activation_cache = softmax(Z)\n",
        "\n",
        "    cache = (linear_cache, activation_cache)\n",
        "    return A, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uatDHqp_Ap09"
      },
      "outputs": [],
      "source": [
        "def L_model_forward(X, parameters):\n",
        "    caches = []\n",
        "    A = X\n",
        "    L = len(parameters) // 2  # number of layers in the neural network\n",
        "    for l in range(1, L):\n",
        "        A_prev = A \n",
        "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)] , \"relu\")\n",
        "        caches.append(cache)\n",
        "\n",
        "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)] , \"softmax\")\n",
        "    caches.append(cache)    \n",
        "          \n",
        "    return AL, caches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bGY-CCvVCIen"
      },
      "outputs": [],
      "source": [
        "def linear_backward(dZ, cache):\n",
        "    A_prev, W, b = cache\n",
        "    m = A_prev.shape[1]\n",
        "\n",
        "    dW = np.dot(dZ, A_prev.T)/m\n",
        "    db = np.sum(dZ, axis=1, keepdims=True)/m\n",
        "    dA_prev = np.dot(W.T, dZ)\n",
        "\n",
        "    return dA_prev, dW, db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ij4nnr1sCMiQ"
      },
      "outputs": [],
      "source": [
        "def linear_activation_backward(dA, cache, activation):\n",
        "    linear_cache, activation_cache = cache\n",
        "    if activation == \"relu\":\n",
        "        dZ = dA*relu_prime(activation_cache)\n",
        "    elif activation == \"sigmoid\":\n",
        "        dZ = dA*sigmoid_prime(activation_cache)\n",
        "    elif activation == \"sum_sqr\":\n",
        "        dZ = dA\n",
        "    \n",
        "    dA_prev, dW, db =  linear_backward(dZ, linear_cache)\n",
        "    \n",
        "    return dA_prev, dW, db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ainDKChAClwR"
      },
      "outputs": [],
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = normalize(Y)\n",
        "    dAL = AL-Y\n",
        "    current_cache = caches[L-1]\n",
        "    grads[\"dA\"+str(L-1)], grads[\"dW\"+str(L)], grads[\"db\"+str(L)] = linear_activation_backward(dAL, current_cache, \"sum_sqr\")\n",
        "    for l in reversed(range(L-1)):\n",
        "        current_cache = caches[l]\n",
        "        grads[\"dA\"+str(l)], grads[\"dW\"+str(l+1)], grads[\"db\"+str(l+1)] = linear_activation_backward(grads[\"dA\"+str(l+1)], current_cache, \"relu\")\n",
        "\n",
        "    return grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fhB5tjuFC02Y"
      },
      "outputs": [],
      "source": [
        "def update_parameters(params, grads, learning_rate):\n",
        "    parameters = params.copy()\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*grads[\"dW\"+str(l+1)]\n",
        "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*grads[\"db\"+str(l+1)]\n",
        "\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EUJMnYTXIgwk"
      },
      "outputs": [],
      "source": [
        "def compute_cost(A, Y):\n",
        "    return 0.5*(np.linalg.norm(Y-A)**2)/Y.size\n",
        "\n",
        "def compute_accuracy(A, Y):\n",
        "    return (np.sum(A==Y)*100)/Y.size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mW0hxgFeRknY"
      },
      "outputs": [],
      "source": [
        "def predict(A):\n",
        "    return np.argmax(A,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PGUeoquhDgcY"
      },
      "outputs": [],
      "source": [
        "def L_layer_model(X, Y, layers_dims, learning_rate = 0.1, num_iterations = 3000, print_cost=False):\n",
        "    np.random.seed(1)\n",
        "    parameters = initialize_parameters_deep(layers_dims)\n",
        "    for i in range(num_iterations):\n",
        "        AL, caches = L_model_forward(X, parameters)\n",
        "        grads = L_model_backward(AL, Y, caches)\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "        \n",
        "        if print_cost and i % 10 == 0 or i == num_iterations - 1:\n",
        "            predictions = predict(AL)\n",
        "            cost = compute_cost(predictions,Y)\n",
        "            print(\"Accuracy after iteration\", i,\": \", compute_accuracy(predictions,Y), \"%\")\n",
        "            print(\"Cost after iteration\", i,\": \", cost)\n",
        "    \n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKRNpiolEBNP",
        "outputId": "fd9c9467-5236-40ee-8c5b-23c94a3e22dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after iteration 0 :  7.906666666666666 %\n",
            "Cost after iteration 0 :  10.6213\n",
            "Accuracy after iteration 10 :  15.451666666666666 %\n",
            "Cost after iteration 10 :  9.974808333333335\n",
            "Accuracy after iteration 20 :  20.48 %\n",
            "Cost after iteration 20 :  10.111108333333332\n",
            "Accuracy after iteration 30 :  28.273333333333333 %\n",
            "Cost after iteration 30 :  8.997283333333334\n",
            "Accuracy after iteration 40 :  32.49333333333333 %\n",
            "Cost after iteration 40 :  8.242583333333334\n",
            "Accuracy after iteration 50 :  34.79666666666667 %\n",
            "Cost after iteration 50 :  8.1083\n",
            "Accuracy after iteration 60 :  38.836666666666666 %\n",
            "Cost after iteration 60 :  7.199066666666667\n",
            "Accuracy after iteration 70 :  46.233333333333334 %\n",
            "Cost after iteration 70 :  5.667233333333333\n",
            "Accuracy after iteration 80 :  55.39 %\n",
            "Cost after iteration 80 :  4.316158333333333\n",
            "Accuracy after iteration 90 :  61.32 %\n",
            "Cost after iteration 90 :  3.482966666666667\n",
            "Accuracy after iteration 100 :  65.22166666666666 %\n",
            "Cost after iteration 100 :  2.947033333333333\n",
            "Accuracy after iteration 110 :  68.64666666666666 %\n",
            "Cost after iteration 110 :  2.5876500000000004\n",
            "Accuracy after iteration 120 :  71.57166666666667 %\n",
            "Cost after iteration 120 :  2.32505\n",
            "Accuracy after iteration 130 :  73.95666666666666 %\n",
            "Cost after iteration 130 :  2.119283333333333\n",
            "Accuracy after iteration 140 :  75.85 %\n",
            "Cost after iteration 140 :  1.9656500000000003\n",
            "Accuracy after iteration 150 :  77.54666666666667 %\n",
            "Cost after iteration 150 :  1.8313166666666667\n",
            "Accuracy after iteration 160 :  79.02166666666666 %\n",
            "Cost after iteration 160 :  1.7174916666666669\n",
            "Accuracy after iteration 170 :  80.22333333333333 %\n",
            "Cost after iteration 170 :  1.6277500000000003\n",
            "Accuracy after iteration 180 :  81.23666666666666 %\n",
            "Cost after iteration 180 :  1.5491916666666667\n",
            "Accuracy after iteration 190 :  82.13166666666666 %\n",
            "Cost after iteration 190 :  1.4729166666666667\n",
            "Accuracy after iteration 200 :  82.87333333333333 %\n",
            "Cost after iteration 200 :  1.409875\n",
            "Accuracy after iteration 210 :  83.57166666666667 %\n",
            "Cost after iteration 210 :  1.3543083333333337\n",
            "Accuracy after iteration 220 :  84.15666666666667 %\n",
            "Cost after iteration 220 :  1.302575\n",
            "Accuracy after iteration 230 :  84.72 %\n",
            "Cost after iteration 230 :  1.2546333333333335\n",
            "Accuracy after iteration 240 :  85.30833333333334 %\n",
            "Cost after iteration 240 :  1.2055333333333333\n",
            "Accuracy after iteration 250 :  85.785 %\n",
            "Cost after iteration 250 :  1.1642416666666666\n",
            "Accuracy after iteration 260 :  86.17833333333333 %\n",
            "Cost after iteration 260 :  1.14\n",
            "Accuracy after iteration 270 :  86.485 %\n",
            "Cost after iteration 270 :  1.1137500000000002\n",
            "Accuracy after iteration 280 :  86.73333333333333 %\n",
            "Cost after iteration 280 :  1.0942833333333333\n",
            "Accuracy after iteration 290 :  87.01 %\n",
            "Cost after iteration 290 :  1.0656249999999998\n",
            "Accuracy after iteration 300 :  87.28833333333333 %\n",
            "Cost after iteration 300 :  1.0437\n",
            "Accuracy after iteration 310 :  87.55333333333333 %\n",
            "Cost after iteration 310 :  1.0212\n",
            "Accuracy after iteration 320 :  87.73833333333333 %\n",
            "Cost after iteration 320 :  1.0091499999999998\n",
            "Accuracy after iteration 330 :  87.92666666666666 %\n",
            "Cost after iteration 330 :  0.9957833333333334\n",
            "Accuracy after iteration 340 :  88.11166666666666 %\n",
            "Cost after iteration 340 :  0.9830583333333334\n",
            "Accuracy after iteration 350 :  88.29666666666667 %\n",
            "Cost after iteration 350 :  0.9704000000000002\n",
            "Accuracy after iteration 360 :  88.45166666666667 %\n",
            "Cost after iteration 360 :  0.9595166666666668\n",
            "Accuracy after iteration 370 :  88.58833333333334 %\n",
            "Cost after iteration 370 :  0.9474999999999999\n",
            "Accuracy after iteration 380 :  88.71166666666667 %\n",
            "Cost after iteration 380 :  0.9389083333333333\n",
            "Accuracy after iteration 390 :  88.85 %\n",
            "Cost after iteration 390 :  0.9302416666666666\n",
            "Accuracy after iteration 400 :  88.97 %\n",
            "Cost after iteration 400 :  0.9216166666666665\n",
            "Accuracy after iteration 410 :  89.06833333333333 %\n",
            "Cost after iteration 410 :  0.9157500000000002\n",
            "Accuracy after iteration 420 :  89.185 %\n",
            "Cost after iteration 420 :  0.9064833333333333\n",
            "Accuracy after iteration 430 :  89.31833333333333 %\n",
            "Cost after iteration 430 :  0.8968833333333333\n",
            "Accuracy after iteration 440 :  89.41833333333334 %\n",
            "Cost after iteration 440 :  0.8905666666666668\n",
            "Accuracy after iteration 450 :  89.50666666666666 %\n",
            "Cost after iteration 450 :  0.884875\n",
            "Accuracy after iteration 460 :  89.59166666666667 %\n",
            "Cost after iteration 460 :  0.8755916666666665\n",
            "Accuracy after iteration 470 :  89.68333333333334 %\n",
            "Cost after iteration 470 :  0.869525\n",
            "Accuracy after iteration 480 :  89.75666666666666 %\n",
            "Cost after iteration 480 :  0.8666833333333335\n",
            "Accuracy after iteration 490 :  89.80333333333333 %\n",
            "Cost after iteration 490 :  0.8634916666666665\n",
            "Accuracy after iteration 500 :  89.89166666666667 %\n",
            "Cost after iteration 500 :  0.8600916666666667\n",
            "Accuracy after iteration 510 :  89.935 %\n",
            "Cost after iteration 510 :  0.8571833333333334\n",
            "Accuracy after iteration 520 :  89.97666666666667 %\n",
            "Cost after iteration 520 :  0.8536416666666665\n",
            "Accuracy after iteration 530 :  90.02833333333334 %\n",
            "Cost after iteration 530 :  0.84935\n",
            "Accuracy after iteration 540 :  90.06833333333333 %\n",
            "Cost after iteration 540 :  0.845275\n",
            "Accuracy after iteration 550 :  90.11 %\n",
            "Cost after iteration 550 :  0.8430583333333334\n",
            "Accuracy after iteration 560 :  90.155 %\n",
            "Cost after iteration 560 :  0.8387416666666667\n",
            "Accuracy after iteration 570 :  90.19166666666666 %\n",
            "Cost after iteration 570 :  0.835425\n",
            "Accuracy after iteration 580 :  90.23 %\n",
            "Cost after iteration 580 :  0.83405\n",
            "Accuracy after iteration 590 :  90.28333333333333 %\n",
            "Cost after iteration 590 :  0.8300666666666665\n",
            "Accuracy after iteration 600 :  90.34333333333333 %\n",
            "Cost after iteration 600 :  0.8248083333333333\n",
            "Accuracy after iteration 610 :  90.37666666666667 %\n",
            "Cost after iteration 610 :  0.8236833333333333\n",
            "Accuracy after iteration 620 :  90.42333333333333 %\n",
            "Cost after iteration 620 :  0.8197916666666667\n",
            "Accuracy after iteration 630 :  90.46166666666667 %\n",
            "Cost after iteration 630 :  0.8177916666666666\n",
            "Accuracy after iteration 640 :  90.51166666666667 %\n",
            "Cost after iteration 640 :  0.8139500000000002\n",
            "Accuracy after iteration 650 :  90.54333333333334 %\n",
            "Cost after iteration 650 :  0.8126083333333333\n",
            "Accuracy after iteration 660 :  90.59333333333333 %\n",
            "Cost after iteration 660 :  0.8093000000000001\n",
            "Accuracy after iteration 670 :  90.645 %\n",
            "Cost after iteration 670 :  0.8056249999999999\n",
            "Accuracy after iteration 680 :  90.67666666666666 %\n",
            "Cost after iteration 680 :  0.8017249999999999\n",
            "Accuracy after iteration 690 :  90.71 %\n",
            "Cost after iteration 690 :  0.7998750000000001\n",
            "Accuracy after iteration 700 :  90.745 %\n",
            "Cost after iteration 700 :  0.7979083333333334\n",
            "Accuracy after iteration 710 :  90.79333333333334 %\n",
            "Cost after iteration 710 :  0.793075\n",
            "Accuracy after iteration 720 :  90.83333333333333 %\n",
            "Cost after iteration 720 :  0.790125\n",
            "Accuracy after iteration 730 :  90.87166666666667 %\n",
            "Cost after iteration 730 :  0.78895\n",
            "Accuracy after iteration 740 :  90.88833333333334 %\n",
            "Cost after iteration 740 :  0.7861\n",
            "Accuracy after iteration 750 :  90.925 %\n",
            "Cost after iteration 750 :  0.7824166666666666\n",
            "Accuracy after iteration 760 :  90.95833333333333 %\n",
            "Cost after iteration 760 :  0.7808250000000001\n",
            "Accuracy after iteration 770 :  90.99 %\n",
            "Cost after iteration 770 :  0.7764166666666668\n",
            "Accuracy after iteration 780 :  91.02166666666666 %\n",
            "Cost after iteration 780 :  0.7747\n",
            "Accuracy after iteration 790 :  91.04333333333334 %\n",
            "Cost after iteration 790 :  0.7723499999999999\n",
            "Accuracy after iteration 800 :  91.09833333333333 %\n",
            "Cost after iteration 800 :  0.7674666666666667\n",
            "Accuracy after iteration 810 :  91.12833333333333 %\n",
            "Cost after iteration 810 :  0.762\n",
            "Accuracy after iteration 820 :  91.15833333333333 %\n",
            "Cost after iteration 820 :  0.7605416666666668\n",
            "Accuracy after iteration 830 :  91.17833333333333 %\n",
            "Cost after iteration 830 :  0.7601249999999998\n",
            "Accuracy after iteration 840 :  91.225 %\n",
            "Cost after iteration 840 :  0.7564333333333334\n",
            "Accuracy after iteration 850 :  91.26 %\n",
            "Cost after iteration 850 :  0.753\n",
            "Accuracy after iteration 860 :  91.29166666666667 %\n",
            "Cost after iteration 860 :  0.7496916666666665\n",
            "Accuracy after iteration 870 :  91.33166666666666 %\n",
            "Cost after iteration 870 :  0.7464333333333333\n",
            "Accuracy after iteration 880 :  91.36166666666666 %\n",
            "Cost after iteration 880 :  0.7448000000000001\n",
            "Accuracy after iteration 890 :  91.405 %\n",
            "Cost after iteration 890 :  0.7400666666666665\n",
            "Accuracy after iteration 900 :  91.41166666666666 %\n",
            "Cost after iteration 900 :  0.7395500000000002\n",
            "Accuracy after iteration 910 :  91.43 %\n",
            "Cost after iteration 910 :  0.7379333333333333\n",
            "Accuracy after iteration 920 :  91.45 %\n",
            "Cost after iteration 920 :  0.7365833333333333\n",
            "Accuracy after iteration 930 :  91.47166666666666 %\n",
            "Cost after iteration 930 :  0.7358500000000001\n",
            "Accuracy after iteration 940 :  91.50166666666667 %\n",
            "Cost after iteration 940 :  0.7342166666666666\n",
            "Accuracy after iteration 950 :  91.52666666666667 %\n",
            "Cost after iteration 950 :  0.7320583333333335\n",
            "Accuracy after iteration 960 :  91.56333333333333 %\n",
            "Cost after iteration 960 :  0.7287666666666667\n",
            "Accuracy after iteration 970 :  91.58666666666667 %\n",
            "Cost after iteration 970 :  0.7260333333333332\n",
            "Accuracy after iteration 980 :  91.605 %\n",
            "Cost after iteration 980 :  0.7249666666666665\n",
            "Accuracy after iteration 990 :  91.625 %\n",
            "Cost after iteration 990 :  0.7243166666666668\n",
            "Accuracy after iteration 999 :  91.665 %\n",
            "Cost after iteration 999 :  0.7213333333333334\n"
          ]
        }
      ],
      "source": [
        "layers_dims = [28*28, 16, 10] \n",
        "parameters = L_layer_model(train_X, train_Y, layers_dims, num_iterations = 1000, print_cost = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9bKCg52NFBp8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy over train set:  91.67166666666667\n",
            "Accuracy over train set:  92.02\n"
          ]
        }
      ],
      "source": [
        "def test(X, parameters):\n",
        "    A,_ = L_model_forward(X, parameters)\n",
        "    predictions = predict(A)\n",
        "    return predictions\n",
        "\n",
        "Y_hat = test(train_X, parameters)\n",
        "accuracy = compute_accuracy(Y_hat, train_Y)\n",
        "print(\"Accuracy over train set: \", accuracy)\n",
        "\n",
        "Y_hat = test(test_X, parameters)\n",
        "accuracy = compute_accuracy(Y_hat, test_Y)\n",
        "print(\"Accuracy over train set: \", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "k0D9WcIL93UL"
      },
      "outputs": [],
      "source": [
        "def visual(index):\n",
        "    tmp = train_X[:, index]\n",
        "    image = tmp.reshape((28, 28)) * 255\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Index: \"+str(index)+\"\\n\"+str(train_Y[index]))\n",
        "    plt.show()\n",
        "\n",
        "    prediction = test(train_X[:, index, None], parameters)\n",
        "    print(\"Result: \", prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GMyNIYniFHJj"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result:  [4]\n"
          ]
        }
      ],
      "source": [
        "visual(index = random.randint(0,9999))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
